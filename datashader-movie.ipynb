{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.colors import inferno, viridis\n",
    "from datashader.transfer_functions import set_background\n",
    "from colorcet import palette\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import holoviews as hv\n",
    "from colorcet import fire\n",
    "import dask.dataframe as dd\n",
    "from colorcet import fire\n",
    "from holoviews.operation.datashader import datashade\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "from holoviews import opts\n",
    "\n",
    "# References\n",
    "# https://casyfill.github.io/posts/2016/08/big_data_mapping/\n",
    "# https://aetperf.github.io/2020/02/13/Lunch-break,-plotting-traffic-injuries-with-datashader.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/geolife_trajectories_1_3.parquet')\n",
    "print(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a video with a zooming into the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat zoom from range 10, 60 > 39.8, 40.1\n",
    "# lon zoom from range 70,140 > 116.2, 116.5\n",
    "\n",
    "#    x_range=(116.2,116.5),\n",
    "#    y_range=(39.8, 40.1),\n",
    "\n",
    "# Define zoom\n",
    "lat_range_start = (10.0, 60.0)\n",
    "lat_range_stop  = (39.8, 40.1)\n",
    "\n",
    "lon_range_start = (70.0,  140.0)\n",
    "lon_range_stop  = (116.2, 116.5)\n",
    "\n",
    "static_frames = 10\n",
    "zoom_steps    = 150\n",
    "\n",
    "west_lat_steps  = np.linspace(lat_range_start[0], lat_range_stop[0], zoom_steps)\n",
    "east_lon_steps  = np.linspace(lon_range_start[0], lon_range_stop[0], zoom_steps)\n",
    "north_lon_steps = np.linspace(lon_range_start[1], lon_range_stop[1], zoom_steps)\n",
    "south_lat_steps = np.linspace(lat_range_start[1], lat_range_stop[1], zoom_steps)\n",
    "\n",
    "x_range = zip(west_lat_steps, east_lon_steps)\n",
    "y_range = zip(south_lat_steps, north_lon_steps)\n",
    "\n",
    "# Plot settings\n",
    "height_to_width = 2\n",
    "width = 800\n",
    "# This scale is used to remove very bright spots as you zoom\n",
    "max_count = np.linspace(8000, 200, zoom_steps)\n",
    "images = []\n",
    "\n",
    "# Static view of all of all the data\n",
    "cvs = ds.Canvas(plot_width=width, plot_height=int(width*height_to_width))\n",
    "agg = cvs.points(df, 'lon', 'lat')\n",
    "agg_values = np.where(agg>max_count[0], max_count[0], agg.values)\n",
    "agg.values = agg_values\n",
    "img = tf.shade(agg,  cmap=palette[\"fire\"], how='log')\n",
    "img = set_background(img, 'black')\n",
    "\n",
    "frame = 0\n",
    "# Generate a bunch of static images for the full map\n",
    "for itt in range(static_frames):\n",
    "    filename = f\"data/movie_0_static_{itt}\"\n",
    "    #filename = \"data/movie_%s_%s_%s\" % (f\"{frame:04}\", \"_\".join([f\"{x:.2f}\" for x in x_range]), \"_\".join([f\"{y:.2f}\" for y in y_range]))\n",
    "    ds.utils.export_image(img, filename, fmt=\".png\")\n",
    "    frame += 1\n",
    "\n",
    "for fig_no, (x_rng, y_rng) in enumerate(zip(x_range, y_range)):\n",
    "    # Zoom towards the target\n",
    "    cvs = ds.Canvas(plot_width=width, plot_height=int(width*height_to_width), x_range=x_rng, y_range=y_rng)\n",
    "    agg = cvs.points(df, 'lon', 'lat')\n",
    "\n",
    "    # Scale values\n",
    "    agg_values = np.where(agg>max_count[fig_no], max_count[fig_no], agg.values)\n",
    "    agg.values = agg_values\n",
    "\n",
    "    img = tf.shade(agg,  cmap=palette[\"fire\"], how='log')\n",
    "    img = set_background(img, 'black')\n",
    "    # Save image if you want to view it later\n",
    "    images.append(img)\n",
    "\n",
    "    filename = f\"data/movie_1_zoom_{fig_no}\"\n",
    "    #filename = \"data/movie_%s_%s_%s\" % (f\"{frame:04}\", \"_\".join([f\"{x:.2f}\" for x in x_rng]), \"_\".join([f\"{y:.2f}\" for y in y_rng]))\n",
    "    ds.utils.export_image(img, filename, fmt=\".png\")\n",
    "    frame += 1\n",
    "\n",
    "for fig_no_extra in range(static_frames):\n",
    "    # Write the last image a couple of extra times to stall the video on the final frame\n",
    "    filename = f\"data/movie_2_final_{fig_no_extra}\"\n",
    "    #filename = \"/data/movie_%s_%s_%s\" % (f\"{frame:04}\", \"_\".join([f\"{x:.2f}\" for x in x_rng]), \"_\".join([f\"{y:.2f}\" for y in y_rng]))\n",
    "    ds.utils.export_image(img, filename, fmt=\".png\")\n",
    "    frame += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the last image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a movie from the images\n",
    "\n",
    "First you need to join the images into a movie using the ffmpeg tool in Linux\n",
    "\n",
    "```bash\n",
    "ffmpeg -y -r 25 -f image2 -pattern_type glob -i 'data/movie_*.png' -vcodec libx264  -crf 25 -pix_fmt yuv420p /data/movie.mp4\n",
    "```\n",
    "This will create a mp4 video in /tmp with 25 frames per second.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
